# Asistente-Conocimiento - Epic Breakdown

**Author:** Andres Amaya Garces
**Date:** 2025-11-10
**Project Level:** Level 3 (Alta Complejidad - Web App + AI Backend + Cumplimiento Normativo)
**Target Scale:** Prototipo funcional (5-10 usuarios concurrentes, 50-100 documentos)

---

## Overview

This document provides the complete epic and story breakdown for Asistente-Conocimiento, decomposing the requirements from the [PRD](./PRD.md) into implementable stories.

### Resumen Ejecutivo de √âpicas

**√âpica 1: Fundaci√≥n e Infraestructura del Proyecto**
- Establecer la base t√©cnica del proyecto (estructura, arquitectura de 3 capas, pipeline b√°sico)
- Historias: 6 historias (configuraci√≥n inicial ‚Üí despliegue base)

**√âpica 2: Gesti√≥n del Conocimiento Corporativo**
- Habilitar captura, almacenamiento y organizaci√≥n del conocimiento organizacional
- Historias: 7 historias (modelos de datos ‚Üí b√∫squeda de documentos)

**√âpica 3: Motor de IA Generativa y Consultas en Lenguaje Natural**
- Implementar RAG y capacidades conversacionales de IA
- Historias: 6 historias (integraci√≥n LLM ‚Üí optimizaci√≥n de rendimiento)

**√âpica 4: Generaci√≥n Autom√°tica de Contenido Formativo**
- Crear material de capacitaci√≥n personalizado autom√°ticamente
- Historias: 5 historias (res√∫menes ‚Üí learning paths)

**√âpica 5: Seguridad, Cumplimiento Normativo y Auditor√≠a**
- Garantizar cumplimiento legal chileno y protecci√≥n de datos
- Historias: 6 historias (autenticaci√≥n ‚Üí control de acceso granular)

**Total: 30 historias de usuario**

---

## Epic 1: Fundaci√≥n e Infraestructura del Proyecto

**Objetivo:** Crear la infraestructura base que habilita todo el desarrollo posterior del prototipo de IA generativa. Esta √©pica establece la arquitectura de 3 capas, el entorno de desarrollo, las dependencias fundamentales, y el pipeline b√°sico de despliegue.

**Valor de Negocio:** Sin esta fundaci√≥n t√©cnica, ninguna historia posterior puede ejecutarse. Es el prerequisito cr√≠tico para el proyecto greenfield.

**Alineaci√≥n con PRD:** RNF3 (Arquitectura Escalable), Sprint 0-1.

---

### Story 1.1: Configuraci√≥n Inicial del Proyecto y Estructura de Carpetas

Como desarrollador del equipo,
Quiero establecer la estructura base del proyecto con todas las carpetas y archivos de configuraci√≥n necesarios,
Para que el equipo tenga un punto de partida organizado y est√°ndar para el desarrollo.

**Acceptance Criteria:**

**Given** que inicio un nuevo proyecto desde cero
**When** ejecuto el script de inicializaci√≥n del proyecto
**Then** se crea la estructura de carpetas est√°ndar:
```
asistente-conocimiento/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ config.py
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ static/
‚îÇ   ‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îî‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îî‚îÄ‚îÄ migrations/
‚îú‚îÄ‚îÄ docs/
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ docker-compose.yml (opcional)
```

**And** se crea un archivo `pyproject.toml` con Poetry y dependencias iniciales:
- fastapi==0.115.0 (framework web)
- sqlmodel==0.0.14 (ORM: SQLAlchemy + Pydantic)
- python-jose[cryptography]==3.3.0 (autenticaci√≥n JWT)
- passlib[bcrypt]==1.7.4 (password hashing)
- python-multipart==0.0.9 (file uploads)
- python-dotenv (variables de entorno)
- pytest (testing)

**And** se crea un archivo `.env.example` con variables de entorno template:
```
DATABASE_URL=sqlite:///./asistente_conocimiento.db
SECRET_KEY=your-secret-key-here
JWT_EXPIRATION_HOURS=24
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b-instruct-q4_K_M
```

**And** el archivo README.md contiene instrucciones b√°sicas de instalaci√≥n y ejecuci√≥n

**Prerequisites:** Ninguno (primera historia del proyecto)

**Technical Notes:**
- Usar Python 3.12 (especificado en architecture.md)
- Instalar Poetry 1.8+ para dependency management
- Incluir `.gitignore` para Python (excluir `__pycache__`, `.env`, `*.pyc`, venv)
- Crear repositorio Git local e inicial commit

---

### Story 1.2: Configuraci√≥n de Base de Datos y Modelos Iniciales

Como desarrollador backend,
Quiero configurar la base de datos relacional con modelos ORM iniciales,
Para que el sistema tenga persistencia de datos desde el inicio del desarrollo.

**Acceptance Criteria:**

**Given** que la estructura del proyecto ya est√° creada (Story 1.1)
**When** configuro la conexi√≥n a la base de datos
**Then** se crea una base de datos SQLite local en `database/asistente_conocimiento.db`

**And** se configuran modelos SQLModel iniciales:
- `User` (id, username, email, hashed_password, full_name, role, is_active, created_at, updated_at)
- `Document` (id, title, category, file_path, file_size, upload_date, user_id, status)
- `AuditLog` (id, user_id, action, resource_type, resource_id, details, ip_address, timestamp)

**And** las migraciones de base de datos se gestionan con Alembic 1.13+

**And** se crea un script `init_db.py` que:
- Crea las tablas
- Inserta usuario admin inicial (username: admin, password: admin123 - solo para desarrollo)
- Inserta categor√≠as predefinidas: "Pol√≠ticas RRHH", "Procedimientos Operativos", "Manuales T√©cnicos"

**And** ejecutar `python init_db.py` deja la base de datos operativa

**Prerequisites:** Story 1.1 completada

**Technical Notes:**
- Usar SQLModel ORM (combina SQLAlchemy + Pydantic) para portabilidad futura (f√°cil migrar a PostgreSQL)
- Passwords NUNCA en texto plano: usar `passlib[bcrypt]` con `pwd_context.hash()`
- Documentar esquema de base de datos en `docs/database-schema.md`
- Considerar constraints: `username` √∫nico, `email` √∫nico, `role` con enum UserRole ('admin', 'user')

---

### Story 1.3: API REST Base con Autenticaci√≥n JWT

Como desarrollador backend,
Quiero implementar una API REST b√°sica con autenticaci√≥n JWT,
Para que el frontend pueda comunicarse de manera segura con el backend desde el inicio.

**Acceptance Criteria:**

**Given** que tengo la base de datos configurada (Story 1.2)
**When** implemento los endpoints b√°sicos de autenticaci√≥n
**Then** existen los siguientes endpoints operativos:

**POST /api/auth/login**
- Body: `{"username": "string", "password": "string"}`
- Response 200: `{"token": "JWT_STRING", "user_id": 1, "role": "admin"}`
- Response 401: `{"error": {"code": "INVALID_CREDENTIALS", "message": "Usuario o contrase√±a incorrectos"}}`

**POST /api/auth/logout** (opcional - JWT es stateless)
- Headers: `Authorization: Bearer {token}`
- Response 200: `{"message": "Logout successful"}`

**GET /api/health** (endpoint p√∫blico sin autenticaci√≥n)
- Response 200: `{"status": "ok", "version": "1.0.0"}`

**And** el token JWT contiene payload:
```json
{
  "user_id": 1,
  "role": "admin",
  "exp": 1699999999  // expiration timestamp (24 horas)
}
```

**And** se implementa middleware `@require_auth` que:
- Valida token JWT en header `Authorization: Bearer {token}`
- Extrae `user_id` y `role` del token
- Retorna 401 si token inv√°lido o expirado

**And** se implementa middleware `@require_role('admin')` para endpoints sensibles

**And** las contrase√±as se validan con `passlib[bcrypt]` usando `pwd_context.verify()`

**Prerequisites:** Story 1.2 completada

**Technical Notes:**
- Usar biblioteca `python-jose[cryptography]` para generaci√≥n y validaci√≥n de tokens JWT
- Secret key debe venir de variable de entorno `SECRET_KEY`
- Token expira en 24 horas (configurable en `.env`)
- Implementar manejo de errores consistente (formato JSON est√°ndar)
- Documentar API en `docs/api-endpoints.md`

---

### Story 1.4: Frontend Base con Sistema de Login

Como usuario del sistema,
Quiero tener una interfaz web b√°sica con login funcional,
Para poder autenticarme y acceder al sistema de manera segura.

**Acceptance Criteria:**

**Given** que la API de autenticaci√≥n est√° operativa (Story 1.3)
**When** accedo a la URL ra√≠z del sistema (`http://localhost:5000/`)
**Then** soy redirigido a la p√°gina de login si no estoy autenticado

**And** la p√°gina de login contiene:
- Logo o t√≠tulo: "Asistente de Conocimiento - Isapre Banm√©dica"
- Campo de texto: Username (requerido)
- Campo de contrase√±a: Password (requerido, input type="password")
- Bot√≥n: "Iniciar Sesi√≥n"
- Mensaje de error visible si login falla

**And** cuando ingreso credenciales v√°lidas y hago click en "Iniciar Sesi√≥n":
- Se env√≠a POST a `/api/auth/login`
- El token JWT se almacena en `sessionStorage`
- Soy redirigido a `/dashboard`

**And** cuando ingreso credenciales inv√°lidas:
- Se muestra mensaje de error: "Usuario o contrase√±a incorrectos"
- Los campos NO se limpian (UX: permitir corregir)

**And** existe una p√°gina `/dashboard` protegida que:
- Verifica presencia de token en sessionStorage
- Si no hay token ‚Üí redirige a `/login`
- Si hay token ‚Üí muestra mensaje "Bienvenido, [username]" y bot√≥n "Cerrar Sesi√≥n"

**And** el bot√≥n "Cerrar Sesi√≥n":
- Elimina token de sessionStorage
- Redirige a `/login`

**Prerequisites:** Story 1.3 completada

**Technical Notes:**
- Frontend: Vite 6.0 + React 18 + TypeScript + shadcn/ui (especificado en architecture.md)
- Almacenar token en `sessionStorage` (se borra al cerrar pesta√±a) NO en `localStorage` por seguridad
- Implementar validaci√≥n de campos en frontend (no enviar si vac√≠os)
- CSS b√°sico: usar framework como Bootstrap o Tailwind para dise√±o profesional r√°pido
- Responsive: funciona en desktop (1920x1080) y tablet (1024x768) m√≠nimo

---

### Story 1.5: Configuraci√≥n de Entorno de Desarrollo con Variables de Entorno

Como desarrollador,
Quiero gestionar configuraciones sensibles (claves API, secrets) mediante variables de entorno,
Para evitar hardcodear secretos en el c√≥digo y facilitar despliegue en m√∫ltiples entornos.

**Acceptance Criteria:**

**Given** que el proyecto tiene dependencias instaladas
**When** creo un archivo `.env` basado en `.env.example`
**Then** el sistema carga variables de entorno autom√°ticamente usando `python-dotenv`

**And** las siguientes variables est√°n configuradas:
```
# Database
DATABASE_URL=sqlite:///./database/asistente_conocimiento.db

# Security
SECRET_KEY=your-super-secret-jwt-key-change-in-production
JWT_EXPIRATION_HOURS=24

# AI Service (Local LLM)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b-instruct-q4_K_M
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=500
LLM_CONTEXT_SIZE=8192

# Environment
ENVIRONMENT=development
DEBUG=True
```

**And** existe un archivo `config.py` que:
- Carga variables de `.env` usando `load_dotenv()`
- Valida que variables cr√≠ticas est√©n presentes (lanza error si faltan)
- Exporta configuraci√≥n como objeto `Config`

**And** el archivo `.env` est√° en `.gitignore` (NUNCA commitear secrets)

**And** el archivo `.env.example` est√° documentado con descripci√≥n de cada variable

**And** el README.md incluye secci√≥n "Configuraci√≥n Inicial":
1. Copiar `.env.example` ‚Üí `.env`
2. Instalar Ollama: `curl https://ollama.ai/install.sh | sh` (Linux/Mac) o descargar desde ollama.ai (Windows)
3. Descargar modelo Llama: `ollama pull llama3.1:8b-instruct-q4_K_M`
4. Generar `SECRET_KEY` √∫nico (comando: `python -c "import secrets; print(secrets.token_hex(32))"`)

**Prerequisites:** Story 1.1 completada

**Technical Notes:**
- Usar biblioteca `python-dotenv`
- Validar presencia de variables cr√≠ticas al inicio (fail-fast)
- Documentar instalaci√≥n de Ollama en `docs/setup-llama-local.md`
- Modelo cuantizado q4_K_M requiere ~8GB RAM m√≠nimo
- Considerar usar diferentes `.env` para dev/test/prod (`.env.development`, `.env.production`)
- **CR√çTICO:** Educar al equipo sobre NUNCA commitear archivos `.env`

---

### Story 1.6: Pipeline B√°sico de CI/CD y Documentaci√≥n de Despliegue

Como miembro del equipo,
Quiero un proceso documentado para ejecutar el proyecto localmente y ejecutar tests,
Para asegurar que cualquier desarrollador pueda levantar el sistema f√°cilmente.

**Acceptance Criteria:**

**Given** que tengo el c√≥digo fuente del proyecto
**When** sigo las instrucciones del README.md
**Then** puedo levantar el proyecto localmente en <10 minutos

**And** el README.md contiene secciones claras:
1. **Requisitos previos:** Python 3.9+, pip, virtualenv
2. **Instalaci√≥n:**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Windows: venv\Scripts\activate
   pip install -r requirements.txt
   cp .env.example .env
   # Editar .env con configuraciones reales
   python init_db.py
   ```
3. **Ejecuci√≥n:**
   ```bash
   python run.py  # o uvicorn app.main:app --reload
   # Sistema disponible en http://localhost:8000
   ```
4. **Testing:**
   ```bash
   pytest tests/
   ```

**And** existe un archivo `run.py` que:
- Carga configuraci√≥n de `.env`
- Inicializa la aplicaci√≥n FastAPI
- Ejecuta servidor en modo desarrollo usando uvicorn

**And** existe una suite de tests inicial (`tests/test_auth.py`):
- Test: Login con credenciales v√°lidas ‚Üí retorna token JWT
- Test: Login con credenciales inv√°lidas ‚Üí retorna 401
- Test: Endpoint protegido sin token ‚Üí retorna 401
- Test: Endpoint protegido con token v√°lido ‚Üí retorna 200

**And** ejecutar `pytest` pasa todos los tests (100% passing)

**And** existe archivo `docs/deployment.md` con:
- Instrucciones para ambiente de desarrollo local
- Troubleshooting com√∫n (ej. "ModuleNotFoundError", problemas de base de datos)

**Prerequisites:** Stories 1.1 - 1.5 completadas

**Technical Notes:**
- Usar `pytest` como framework de testing
- Configurar pytest con `pytest.ini` o `setup.cfg`
- Tests deben usar base de datos de prueba separada (no sobrescribir desarrollo)
- Opcional: Configurar GitHub Actions para CI autom√°tico (ejecutar tests en cada push)
- Documentar arquitectura de 3 capas en `docs/arquitectura.md`

---

## Epic 2: Gesti√≥n del Conocimiento Corporativo

**Objetivo:** Habilitar la captura, almacenamiento, procesamiento y organizaci√≥n del conocimiento organizacional. Esta √©pica implementa el repositorio de conocimiento que ser√° la base de datos para el motor de IA.

**Valor de Negocio:** Resolver el problema de "conocimiento fragmentado" permitiendo centralizar documentos corporativos de manera estructurada, indexada y consultable. Sin esta √©pica, la IA no tendr√≠a fuente de conocimiento corporativo.

**Alineaci√≥n con PRD:** RF1 (Registro y Almacenamiento de Conocimiento), RF3 (Gesti√≥n Documental), Sprint 2.

---

### Story 2.1: Modelos de Datos para Documentos y Metadatos

Como desarrollador backend,
Quiero extender los modelos de datos para soportar documentos con metadatos ricos,
Para que el sistema pueda almacenar y consultar informaci√≥n estructurada sobre cada documento.

**Acceptance Criteria:**

**Given** que tengo la base de datos configurada (Epic 1)
**When** extiendo el modelo `Document` en SQLModel
**Then** el modelo `Document` contiene los siguientes campos:
- `id` (Integer, Primary Key, Auto-increment)
- `title` (String(200), Not Null, Indexado)
- `description` (Text, Nullable)
- `file_path` (String(500), Not Null, Unique)
- `file_type` (String(10), Not Null) // 'pdf', 'txt'
- `file_size_bytes` (Integer, Not Null)
- `category` (String(100), Not Null, Indexado)
- `upload_date` (DateTime, Not Null, Default: now())
- `uploaded_by` (Integer, Foreign Key ‚Üí User.id)
- `content_text` (Text, Nullable) // Texto extra√≠do del documento
- `is_indexed` (Boolean, Default: False)
- `indexed_at` (DateTime, Nullable)

**And** se crea un modelo `DocumentCategory`:
- `id` (Integer, Primary Key)
- `name` (String(100), Unique, Not Null)
- `description` (Text, Nullable)
- `created_at` (DateTime, Default: now())

**And** la relaci√≥n entre modelos est√° definida:
- `Document.uploaded_by` ‚Üí FK a `User.id` (relaci√≥n many-to-one)
- `Document.category` ‚Üí referencia a `DocumentCategory.name`

**And** se crea migraci√≥n de base de datos que:
- Agrega nuevas columnas a tabla `documents`
- Crea tabla `document_categories`
- Inserta categor√≠as predefinidas: "Pol√≠ticas RRHH", "Procedimientos Operativos", "Manuales T√©cnicos", "FAQs", "Normativas"

**And** ejecutar migraci√≥n actualiza la base de datos sin perder datos existentes

**Prerequisites:** Epic 1 completada (especialmente Story 1.2)

**Technical Notes:**
- Usar Alembic para migraciones (mantener historial de cambios en esquema)
- `content_text` almacena texto extra√≠do de PDF/TXT para indexaci√≥n full-text
- `is_indexed` flag permite procesar indexaci√≥n en background sin bloquear carga
- Considerar √≠ndices en: `title`, `category`, `upload_date` (para b√∫squedas r√°pidas)
- Documentar modelo actualizado en `docs/database-schema.md`

---

### Story 2.2: API de Carga de Documentos con Validaci√≥n

Como administrador,
Quiero cargar documentos (PDF, TXT) al sistema mediante una API REST,
Para centralizar el conocimiento organizacional de manera segura y validada.

**Acceptance Criteria:**

**Given** que estoy autenticado como administrador (Story 1.3)
**When** implemento el endpoint de carga de documentos
**Then** existe el endpoint:

**POST /api/knowledge/upload**
- Headers: `Authorization: Bearer {admin_token}`, `Content-Type: multipart/form-data`
- Body (form-data):
  - `file` (archivo, requerido)
  - `title` (string, requerido, max 200 chars)
  - `description` (string, opcional, max 1000 chars)
  - `category` (string, requerido, debe existir en `DocumentCategory`)
- Response 201:
  ```json
  {
    "document_id": 1,
    "title": "Manual de Procedimientos",
    "file_path": "/uploads/manual_procedimientos_20251110.pdf",
    "status": "uploaded",
    "message": "Documento cargado exitosamente. Indexaci√≥n en progreso."
  }
  ```

**And** el sistema valida:
- Formato de archivo: solo PDF y TXT (rechazar otros con error 400)
- Tama√±o m√°ximo: 10MB (rechazar mayores con error 413)
- Categor√≠a existe en base de datos (rechazar si no existe con error 400)
- Usuario tiene rol 'admin' (rechazar si 'user' con error 403)

**And** cuando la validaci√≥n es exitosa:
- Archivo se guarda en directorio `/uploads/` con nombre √∫nico: `{sanitized_title}_{timestamp}.{ext}`
- Se crea registro en tabla `documents` con estado `is_indexed=False`
- Se registra en `audit_logs`: evento "DOCUMENT_UPLOADED"

**And** cuando la validaci√≥n falla:
- Response 400: `{"error": {"code": "INVALID_FILE_TYPE", "message": "Solo se permiten archivos PDF y TXT"}}`
- Response 413: `{"error": {"code": "FILE_TOO_LARGE", "message": "El archivo excede el l√≠mite de 10MB"}}`
- Response 400: `{"error": {"code": "INVALID_CATEGORY", "message": "La categor√≠a especificada no existe"}}`

**Prerequisites:** Story 2.1 completada

**Technical Notes:**
- Usar validaci√≥n Pydantic (dentro de SQLModel) para sanitizar nombres de archivo o `pathlib.Path`
- Crear directorio `/uploads/` si no existe (usar `os.makedirs(exist_ok=True)`)
- Almacenar `file_size_bytes` calculado de archivo subido
- Validar extensi√≥n de archivo en backend (no confiar en MIME type del cliente)
- Implementar en `backend/app/routes/knowledge.py`
- Agregar tests: carga exitosa, validaci√≥n de formato, validaci√≥n de tama√±o, autorizaci√≥n

---

### Story 2.3: Extracci√≥n de Texto de Documentos PDF y TXT

Como sistema,
Quiero extraer autom√°ticamente el texto de documentos cargados (PDF y TXT),
Para poder indexar el contenido y hacerlo consultable por la IA.

**Acceptance Criteria:**

**Given** que un documento fue cargado exitosamente (Story 2.2)
**When** el sistema procesa el archivo
**Then** si el archivo es TXT:
- Se lee el contenido completo del archivo
- Se almacena en `Document.content_text`
- Se marca `is_indexed=True`, `indexed_at=now()`

**And** si el archivo es PDF:
- Se usa biblioteca de extracci√≥n de texto (PyPDF2 o pdfplumber)
- Se extrae texto de todas las p√°ginas
- Se limpia el texto (eliminar caracteres especiales, normalizar espacios)
- Se almacena en `Document.content_text`
- Se marca `is_indexed=True`, `indexed_at=now()`

**And** si la extracci√≥n falla:
- Se registra error en logs
- Se marca `is_indexed=False` (permitir reintento manual)
- Se actualiza `Document.description` agregando nota: "[ERROR: No se pudo extraer texto]"

**And** la extracci√≥n ocurre de manera **as√≠ncrona** (no bloquea respuesta de upload):
- Endpoint `/upload` retorna inmediatamente tras guardar archivo
- Proceso de indexaci√≥n se ejecuta en background (usar threading o task queue)

**And** existe endpoint para verificar estado de indexaci√≥n:
**GET /api/knowledge/documents/{document_id}/status**
- Response: `{"document_id": 1, "is_indexed": true, "indexed_at": "2025-11-10T10:30:00Z"}`

**Prerequisites:** Story 2.2 completada

**Technical Notes:**
- **Opci√≥n 1:** Usar `PyPDF2` (m√°s ligero, puede fallar con PDFs complejos)
- **Opci√≥n 2:** Usar `pdfplumber` (m√°s robusto, maneja mejor PDFs escaneados)
- **Opci√≥n 3:** Usar `PyMuPDF (fitz)` (m√°s r√°pido, mejor para PDFs grandes)
- Implementar procesamiento as√≠ncrono con `threading` o librer√≠a `celery` (si necesario)
- Limitar `content_text` a primeros 50,000 caracteres (evitar sobrecarga de memoria)
- Loggear tiempo de extracci√≥n (m√©trica de rendimiento)
- Agregar tests: extracci√≥n TXT exitosa, extracci√≥n PDF exitosa, manejo de error PDF corrupto

---

### Story 2.4: Indexaci√≥n Full-Text para B√∫squeda R√°pida

Como sistema,
Quiero crear un √≠ndice invertido del contenido de documentos,
Para permitir b√∫squedas r√°pidas de palabras clave y relevancia sem√°ntica.

**Acceptance Criteria:**

**Given** que los documentos tienen texto extra√≠do (Story 2.3)
**When** implemento el sistema de indexaci√≥n
**Then** se crea un √≠ndice full-text sobre la columna `Document.content_text`

**And** el sistema usa **SQLite FTS5** (Full-Text Search):
- Se crea tabla virtual: `documents_fts` usando FTS5
- Se sincronizan autom√°ticamente cambios de `documents.content_text` a `documents_fts`
- Soporta b√∫squeda de palabras clave con ranking de relevancia

**And** existe endpoint de b√∫squeda:
**GET /api/knowledge/search**
- Headers: `Authorization: Bearer {token}`
- Query params: `?q=reembolso&limit=10&offset=0`
- Response 200:
  ```json
  {
    "query": "reembolso",
    "total_results": 5,
    "results": [
      {
        "document_id": 3,
        "title": "Procedimiento de Reembolsos",
        "category": "Procedimientos Operativos",
        "relevance_score": 0.95,
        "snippet": "...proceso de reembolso especial requiere..."
      }
    ]
  }
  ```

**And** la b√∫squeda soporta:
- Palabras clave individuales: `?q=vacaciones`
- Frases exactas: `?q="pol√≠ticas de RRHH"`
- Operadores booleanos: `?q=reembolso AND urgente`
- Ranking por relevancia (TF-IDF impl√≠cito en FTS5)

**And** los resultados incluyen:
- Snippet de contexto (100 caracteres alrededor de match)
- Score de relevancia normalizado (0.0 - 1.0)
- Paginaci√≥n (limit/offset)

**Prerequisites:** Story 2.3 completada

**Technical Notes:**
- SQLite FTS5 est√° disponible desde SQLite 3.9.0+ (verificar versi√≥n)
- Crear triggers para sincronizar `documents` ‚Üí `documents_fts` autom√°ticamente
- Configurar tokenizer en espa√±ol: `tokenize='unicode61 remove_diacritics 2'`
- Limitar snippet a 150 caracteres (performance)
- Implementar en `backend/app/services/search_service.py`
- Agregar tests: b√∫squeda por palabra clave, b√∫squeda por frase, resultados vac√≠os, paginaci√≥n

---

### Story 2.5: API de Consulta y Listado de Documentos

Como usuario (admin o user),
Quiero consultar la lista de documentos disponibles con filtros,
Para explorar el repositorio de conocimiento y encontrar informaci√≥n relevante.

**Acceptance Criteria:**

**Given** que estoy autenticado (Story 1.3)
**When** implemento endpoints de consulta de documentos
**Then** existen los siguientes endpoints:

**GET /api/knowledge/documents**
- Headers: `Authorization: Bearer {token}`
- Query params (todos opcionales):
  - `?category=Pol√≠ticas RRHH` (filtrar por categor√≠a)
  - `?limit=20&offset=0` (paginaci√≥n)
  - `?sort_by=upload_date&order=desc` (ordenamiento)
- Response 200:
  ```json
  {
    "total": 50,
    "limit": 20,
    "offset": 0,
    "documents": [
      {
        "id": 5,
        "title": "Manual de Vacaciones",
        "description": "Pol√≠ticas de solicitud de vacaciones",
        "category": "Pol√≠ticas RRHH",
        "file_type": "pdf",
        "file_size_bytes": 524288,
        "upload_date": "2025-11-01T10:00:00Z",
        "uploaded_by": "admin"
      }
    ]
  }
  ```

**GET /api/knowledge/documents/{document_id}**
- Headers: `Authorization: Bearer {token}`
- Response 200:
  ```json
  {
    "id": 5,
    "title": "Manual de Vacaciones",
    "description": "...",
    "category": "Pol√≠ticas RRHH",
    "file_type": "pdf",
    "file_size_bytes": 524288,
    "file_path": "/uploads/manual_vacaciones.pdf",
    "upload_date": "2025-11-01T10:00:00Z",
    "uploaded_by": "admin",
    "is_indexed": true,
    "indexed_at": "2025-11-01T10:01:00Z"
  }
  ```
- Response 404 si documento no existe

**GET /api/knowledge/categories**
- Headers: `Authorization: Bearer {token}`
- Response 200:
  ```json
  {
    "categories": [
      {"name": "Pol√≠ticas RRHH", "document_count": 15},
      {"name": "Procedimientos Operativos", "document_count": 23}
    ]
  }
  ```

**And** la paginaci√≥n por defecto es: `limit=20, offset=0`

**And** el ordenamiento soporta: `upload_date`, `title`, `file_size_bytes` (order: `asc` o `desc`)

**Prerequisites:** Story 2.4 completada

**Technical Notes:**
- Implementar filtros con query builder de SQLModel (evitar SQL injection)
- Usuario 'user' puede listar documentos (solo lectura)
- Retornar `uploaded_by` como username (no user_id)
- Implementar en `backend/app/routes/knowledge.py`
- Agregar tests: listado sin filtros, filtrado por categor√≠a, paginaci√≥n, ordenamiento

---

### Story 2.6: Descarga y Visualizaci√≥n de Documentos

Como usuario (admin o user),
Quiero descargar y visualizar documentos del repositorio,
Para acceder al contenido completo y validar informaci√≥n.

**Acceptance Criteria:**

**Given** que estoy autenticado (Story 1.3)
**When** implemento endpoint de descarga
**Then** existe el endpoint:

**GET /api/knowledge/documents/{document_id}/download**
- Headers: `Authorization: Bearer {token}`
- Response 200:
  - Content-Type: `application/pdf` o `text/plain` seg√∫n `file_type`
  - Content-Disposition: `attachment; filename="manual_vacaciones.pdf"`
  - Body: contenido binario del archivo

**And** si el documento no existe:
- Response 404: `{"error": {"code": "DOCUMENT_NOT_FOUND", "message": "El documento solicitado no existe"}}`

**And** si el usuario no est√° autenticado:
- Response 401: error de autenticaci√≥n

**And** la descarga se registra en `audit_logs`:
- Evento: "DOCUMENT_DOWNLOADED"
- Detalles: `{"document_id": 5, "user_id": 2, "timestamp": "..."}`

**And** existe endpoint de previsualizaci√≥n (opcional para MVP):
**GET /api/knowledge/documents/{document_id}/preview**
- Retorna primeros 500 caracteres de `content_text`
- Usado para mostrar preview en UI sin descargar archivo completo

**Prerequisites:** Story 2.5 completada

**Technical Notes:**
- Usar `flask.send_file()` o equivalente en FastAPI para servir archivos
- Validar que `file_path` existe en filesystem antes de servir (manejar archivos hu√©rfanos)
- Sanitizar `filename` en header Content-Disposition (evitar inyecci√≥n de headers)
- Considerar rate limiting (evitar descarga masiva automatizada)
- Implementar en `backend/app/routes/knowledge.py`
- Agregar tests: descarga exitosa PDF, descarga exitosa TXT, documento no existe, sin autenticaci√≥n

---

### Story 2.7: Eliminaci√≥n de Documentos con Auditor√≠a

Como administrador,
Quiero eliminar documentos del repositorio de manera segura con trazabilidad,
Para mantener el repositorio actualizado y cumplir con pol√≠ticas de retenci√≥n de datos.

**Acceptance Criteria:**

**Given** que estoy autenticado como administrador (rol 'admin')
**When** implemento endpoint de eliminaci√≥n
**Then** existe el endpoint:

**DELETE /api/knowledge/documents/{document_id}**
- Headers: `Authorization: Bearer {admin_token}`
- Response 200:
  ```json
  {
    "message": "Documento eliminado exitosamente",
    "document_id": 5,
    "title": "Manual de Vacaciones"
  }
  ```

**And** al eliminar el documento:
1. Se elimina archivo f√≠sico del directorio `/uploads/`
2. Se elimina registro de tabla `documents`
3. Se elimina entrada correspondiente en `documents_fts` (√≠ndice full-text)
4. Se registra en `audit_logs`:
   - Evento: "DOCUMENT_DELETED"
   - Detalles: `{"document_id": 5, "title": "Manual de Vacaciones", "deleted_by": 1}`

**And** si el usuario no es administrador:
- Response 403: `{"error": {"code": "FORBIDDEN", "message": "Solo administradores pueden eliminar documentos"}}`

**And** si el documento no existe:
- Response 404: `{"error": {"code": "DOCUMENT_NOT_FOUND", "message": "El documento solicitado no existe"}}`

**And** si el archivo f√≠sico no existe (hu√©rfano):
- Eliminar registro de base de datos de todos modos
- Loggear warning: "Archivo f√≠sico no encontrado durante eliminaci√≥n"
- Retornar Response 200 (operaci√≥n exitosa desde perspectiva del usuario)

**And** en el frontend (opcional para esta historia):
- Mostrar confirmaci√≥n: "¬øEst√°s seguro de eliminar '{title}'?" antes de enviar DELETE
- Mostrar notificaci√≥n de √©xito tras eliminaci√≥n

**Prerequisites:** Story 2.6 completada

**Technical Notes:**
- Usar `os.remove()` para eliminar archivo f√≠sico (manejar exception si no existe)
- Implementar transacci√≥n de base de datos (rollback si falla eliminaci√≥n de archivo)
- Considerar "soft delete" como alternativa: marcar `is_deleted=True` en lugar de eliminar f√≠sicamente (mejor para auditor√≠a)
- Implementar en `backend/app/routes/knowledge.py`
- Agregar tests: eliminaci√≥n exitosa, sin permisos (user intenta eliminar), documento no existe, manejo de archivo hu√©rfano

---

## Epic 3: Motor de IA Generativa y Consultas en Lenguaje Natural

**Objetivo:** Implementar el motor de IA generativa con t√©cnica RAG (Retrieval-Augmented Generation) que permite a los usuarios consultar el conocimiento corporativo en lenguaje natural y recibir respuestas contextualizadas y precisas.

**Valor de Negocio:** Esta es la "magia" del producto. Transforma el conocimiento t√°cito en expl√≠cito mediante IA conversacional que responde en <2 segundos con informaci√≥n verificable y trazable.

**Alineaci√≥n con PRD:** RF2 (Consultas en Lenguaje Natural), RNF2 (Rendimiento <2s), Secci√≥n "Innovation & Novel Patterns" (RAG con cumplimiento normativo).

---

### Story 3.1: Configuraci√≥n e Integraci√≥n de Llama 3.1 Local v√≠a Ollama

Como desarrollador backend,
Quiero integrar un modelo de lenguaje local (Llama 3.1) ejecut√°ndose en el servidor,
Para que el sistema genere respuestas de IA sin dependencia de APIs externas y con total soberan√≠a de datos.

**Acceptance Criteria:**

**Given** que necesito un motor de IA generativa local
**When** configuro Ollama y Llama 3.1
**Then** el servidor tiene Ollama instalado y ejecut√°ndose:
- Ollama versi√≥n ‚â•0.1.20
- Servicio corriendo en `http://localhost:11434`
- Modelo `llama3.1:8b-instruct-q4_K_M` descargado (tama√±o ~4.7GB)

**And** se valida disponibilidad del modelo:
```bash
$ ollama list
NAME                          SIZE    MODIFIED
llama3.1:8b-instruct-q4_K_M  4.7GB   2 hours ago
```

**And** existe m√≥dulo `backend/app/services/llm_service.py`:
```python
import requests
from typing import Dict

class LlamaService:
    def __init__(self, base_url: str = "http://localhost:11434"):
        self.base_url = base_url
        self.model = "llama3.1:8b-instruct-q4_K_M"

    def generate_response(
        self,
        prompt: str,
        context: str = "",
        temperature: float = 0.3,
        max_tokens: int = 500
    ) -> Dict:
        """
        Genera respuesta usando Llama 3.1 local.

        Returns: {"response": str, "tokens_generated": int, "generation_time_ms": float}
        """
        full_prompt = self._build_rag_prompt(context, prompt)

        response = requests.post(
            f"{self.base_url}/api/generate",
            json={
                "model": self.model,
                "prompt": full_prompt,
                "temperature": temperature,
                "num_predict": max_tokens,
                "stream": False
            },
            timeout=30
        )

        if response.status_code != 200:
            raise LLMServiceException(f"Ollama error: {response.text}")

        result = response.json()
        return {
            "response": result["response"],
            "tokens_generated": result.get("eval_count", 0),
            "generation_time_ms": result.get("total_duration", 0) / 1e6
        }

    def _build_rag_prompt(self, context: str, query: str) -> str:
        """Construye prompt optimizado para RAG con Llama 3.1"""
        return f"""<|begin_of_text|><|start_header_id|>system<|end_header_id|>

Eres un asistente de conocimiento corporativo. Responde preguntas bas√°ndote EXCLUSIVAMENTE en el contexto proporcionado.
Si la informaci√≥n no est√° en el contexto, responde: "No encuentro informaci√≥n sobre eso en la base de conocimiento."

<|eot_id|><|start_header_id|>user<|end_header_id|>

**Contexto:**
{context}

**Pregunta:** {query}

<|eot_id|><|start_header_id|>assistant<|end_header_id|>

"""

    def health_check(self) -> bool:
        """Verifica que Ollama est√© disponible"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            return response.status_code == 200
        except:
            return False
```

**And** se implementa endpoint de health check:
**GET /api/ia/health**
- Verifica que Ollama est√© corriendo
- Verifica que modelo Llama 3.1 est√© disponible
- Response 200: `{"status": "ok", "model": "llama3.1:8b-instruct-q4_K_M", "ollama_version": "0.1.20"}`
- Response 503: `{"status": "unavailable", "error": "Ollama service not running"}`

**And** se maneja gracefully si Ollama no est√° disponible:
- Al iniciar backend: loggea WARNING si Ollama no responde
- En consultas: retorna error claro "Servicio de IA temporalmente no disponible"
- No bloquea inicio de la aplicaci√≥n (otras funcionalidades siguen operativas)

**And** configuraci√≥n en `.env`:
```
# Local LLM Service
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b-instruct-q4_K_M
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=500
LLM_CONTEXT_SIZE=8192
```

**And** loggea m√©tricas de inferencia:
- Tiempo de generaci√≥n (ms)
- Tokens generados
- Errores de conexi√≥n con Ollama

**And** existen tests:
```python
def test_llama_service_generates_response():
    service = LlamaService()
    result = service.generate_response(
        prompt="¬øQu√© es RAG?",
        context="RAG significa Retrieval-Augmented Generation..."
    )
    assert "response" in result
    assert len(result["response"]) > 0
    assert result["generation_time_ms"] < 10000  # <10s

def test_llama_service_health_check():
    service = LlamaService()
    assert service.health_check() == True

def test_llama_service_handles_ollama_down():
    service = LlamaService(base_url="http://localhost:9999")  # puerto incorrecto
    with pytest.raises(LLMServiceException):
        service.generate_response("test", "")
```

**Prerequisites:** Story 1.5 (variables de entorno) completada

**Technical Notes:**
- **Instalaci√≥n Ollama:**
  - Linux/Mac: `curl https://ollama.ai/install.sh | sh`
  - Windows: Descargar instalador desde ollama.ai
- **Pull modelo:** `ollama pull llama3.1:8b-instruct-q4_K_M` (~4.7GB download)
- **Requerimientos hardware:**
  - M√≠nimo: 8GB RAM (modelo cuantizado q4)
  - Recomendado: 16GB RAM + GPU (NVIDIA con CUDA)
  - Rendimiento CPU: ~10-15 tokens/s
  - Rendimiento GPU: ~40-60 tokens/s
- **Formato de prompt:** Usar template Llama 3.1 oficial con tags `<|start_header_id|>`
- **Alternativa a Ollama:** llama.cpp si necesitas m√°s control fino (m√°s complejo)
- **Documentar en:** `docs/setup-llama-local.md`
- **Fallback:** Si rendimiento es insuficiente, considerar modelo m√°s peque√±o: `llama3.1:3b` o `phi3:mini`

---

### Story 3.2: Implementaci√≥n de Retrieval (B√∫squeda de Documentos Relevantes)

Como sistema,
Quiero recuperar los documentos m√°s relevantes del repositorio para una consulta de usuario,
Para proporcionar contexto preciso al LLM y evitar alucinaciones.

**Acceptance Criteria:**

**Given** que el sistema tiene documentos indexados (Epic 2, Story 2.4)
**When** implemento el servicio de recuperaci√≥n (Retrieval)
**Then** existe funci√≥n `retrieve_relevant_documents(query: str, top_k: int = 3) -> List[Document]`

**And** la funci√≥n:
1. Toma la consulta del usuario (ej. "¬øC√≥mo solicito vacaciones?")
2. Busca en el √≠ndice full-text (SQLite FTS5) documentos que contengan palabras clave
3. Rankea documentos por relevancia (score de FTS5)
4. Retorna top K documentos m√°s relevantes (por defecto K=3)

**And** cada documento retornado incluye:
- `document_id`
- `title`
- `category`
- `content_snippet` (fragmento relevante, m√°ximo 1000 caracteres)
- `relevance_score` (0.0 - 1.0)

**And** si no encuentra documentos relevantes (score < 0.1):
- Retorna lista vac√≠a
- Loggea evento: "No se encontraron documentos relevantes para: {query}"

**And** optimiza la b√∫squeda:
- Expande consulta con sin√≥nimos (opcional para MVP)
  - Ej. "vacaciones" ‚Üí tambi√©n buscar "permiso", "ausencia"
- Normaliza texto: lowercase, eliminar acentos
- Filtra stopwords en espa√±ol ("el", "la", "de", "en")

**And** existe endpoint de prueba (√∫til para debugging):
**POST /api/ia/retrieve** (solo admin)
- Body: `{"query": "reembolso urgente"}`
- Response:
  ```json
  {
    "query": "reembolso urgente",
    "documents_found": 3,
    "documents": [
      {
        "document_id": 5,
        "title": "Procedimiento Reembolsos",
        "relevance_score": 0.92,
        "snippet": "...reembolso urgente requiere aprobaci√≥n..."
      }
    ]
  }
  ```

**Prerequisites:** Epic 2 completada (especialmente Story 2.4 indexaci√≥n)

**Technical Notes:**
- Reusar servicio de b√∫squeda de Story 2.4 (`search_service.py`)
- Configurar `top_k` como variable de entorno `RAG_TOP_K_DOCUMENTS=3`
- Considerar b√∫squeda h√≠brida: keyword (FTS5) + semantic (embeddings) - semantic es Growth Feature
- Para MVP: solo keyword search es suficiente
- Limitar snippet a contexto relevante (100 caracteres antes/despu√©s del match)
- Implementar en `backend/app/services/retrieval_service.py`
- Agregar tests: b√∫squeda exitosa, sin resultados, m√∫ltiples documentos

---

### Story 3.3: Implementaci√≥n de RAG (Retrieval-Augmented Generation)

Como sistema,
Quiero combinar recuperaci√≥n de documentos con generaci√≥n de respuestas por LLM,
Para proporcionar respuestas precisas fundamentadas en conocimiento corporativo verificable.

**Acceptance Criteria:**

**Given** que tengo integraci√≥n con LLM (Story 3.1) y servicio de retrieval (Story 3.2)
**When** implemento el pipeline RAG completo
**Then** existe funci√≥n `rag_query(user_query: str, user_id: int) -> dict`:

**Pipeline RAG:**
1. **Retrieval:** Recupera top 3 documentos relevantes usando `retrieve_relevant_documents(user_query)`
2. **Context Construction:** Combina snippets de documentos en contexto:
   ```
   Documento 1 (Procedimiento Reembolsos):
   ...reembolso urgente requiere aprobaci√≥n de supervisor...

   Documento 2 (Pol√≠ticas RRHH):
   ...reembolsos se procesan en 5 d√≠as h√°biles...
   ```
3. **Augmentation:** Construye prompt aumentado con contexto
4. **Generation:** Env√≠a prompt + contexto al LLM usando `generate_response()`
5. **Response Formatting:** Formatea respuesta con referencias a fuentes

**And** retorna objeto:
```python
{
  "answer": "Para solicitar un reembolso urgente, necesitas aprobaci√≥n de tu supervisor seg√∫n el Procedimiento de Reembolsos...",
  "sources": [
    {"document_id": 5, "title": "Procedimiento Reembolsos", "relevance_score": 0.92},
    {"document_id": 7, "title": "Pol√≠ticas RRHH", "relevance_score": 0.78}
  ],
  "response_time_ms": 1850,
  "documents_retrieved": 3
}
```

**And** si no encuentra documentos relevantes:
- NO env√≠a request al LLM (ahorro de costos)
- Retorna mensaje:
  ```python
  {
    "answer": "No encontr√© informaci√≥n espec√≠fica sobre tu consulta en la base de conocimiento. ¬øPodr√≠as reformular tu pregunta o usar palabras clave diferentes?",
    "sources": [],
    "response_time_ms": 50,
    "documents_retrieved": 0
  }
  ```

**And** incluye disclaimer en respuestas generadas:
- Agrega al final de `answer`: "\n\n*Nota: Esta respuesta fue generada por IA. Verifica con tu supervisor si tienes dudas.*"

**And** loggea m√©tricas:
- Tiempo total del pipeline (retrieval + generation)
- N√∫mero de documentos recuperados
- Score promedio de relevancia
- Tokens utilizados por el LLM

**Prerequisites:** Stories 3.1 y 3.2 completadas

**Technical Notes:**
- Implementar en `backend/app/services/rag_service.py`
- Medir tiempos de cada fase del pipeline (profiling)
- Limitar contexto total a ~2000 caracteres (evitar exceder l√≠mites de tokens del LLM)
- Si contexto excede l√≠mite: priorizar documentos con mayor relevance_score
- Implementar cach√© de respuestas: consultas id√©nticas en <5 minutos retornan cached response
- Agregar tests: pipeline completo exitoso, sin documentos relevantes, timeout del LLM

---

### Story 3.4: API de Consulta Conversacional para Usuarios

Como usuario (admin o user),
Quiero consultar el conocimiento corporativo en lenguaje natural mediante una API,
Para obtener respuestas r√°pidas y precisas fundamentadas en documentos verificables.

**Acceptance Criteria:**

**Given** que estoy autenticado (Story 1.3)
**When** implemento el endpoint de consulta IA
**Then** existe el endpoint:

**POST /api/ia/query**
- Headers: `Authorization: Bearer {token}`
- Body:
  ```json
  {
    "query": "¬øC√≥mo proceso un reembolso urgente?",
    "context_mode": "general"  // opcional: "general" o "specific"
  }
  ```
- Response 200:
  ```json
  {
    "query": "¬øC√≥mo proceso un reembolso urgente?",
    "answer": "Para procesar un reembolso urgente, necesitas...",
    "sources": [
      {
        "document_id": 5,
        "title": "Procedimiento Reembolsos",
        "category": "Procedimientos Operativos",
        "relevance_score": 0.92
      }
    ],
    "response_time_ms": 1850,
    "timestamp": "2025-11-10T10:30:00Z"
  }
  ```

**And** valida la entrada:
- `query` es requerido (m√≠nimo 10 caracteres, m√°ximo 500)
- Si `query` es muy corto: Response 400 "La consulta debe tener al menos 10 caracteres"
- Si `query` es muy largo: Response 400 "La consulta no puede exceder 500 caracteres"

**And** ejecuta el pipeline RAG:
- Llama a `rag_query(user_query, user_id)` de Story 3.3
- Retorna respuesta formateada

**And** registra en base de datos:
- Crea tabla `queries` si no existe:
  - `id`, `user_id`, `query_text`, `answer_text`, `response_time_ms`, `timestamp`, `sources_json`
- Inserta registro de cada consulta (√∫til para an√°lisis y mejora continua)

**And** registra en audit logs:
- Evento: "AI_QUERY"
- Detalles: `{"user_id": 2, "query": "...", "response_time_ms": 1850, "sources_count": 3}`

**And** maneja errores del LLM:
- Si LLM falla (Story 3.1 lanza exception):
  - Response 503: `{"error": {"code": "AI_SERVICE_UNAVAILABLE", "message": "El servicio de IA no est√° disponible temporalmente. Intenta nuevamente."}}`
- Si timeout:
  - Response 504: `{"error": {"code": "AI_TIMEOUT", "message": "La consulta tard√≥ demasiado. Intenta con una pregunta m√°s espec√≠fica."}}`

**And** implementa rate limiting b√°sico:
- M√°ximo 10 consultas por minuto por usuario
- Si excede: Response 429 "Demasiadas consultas. Espera un momento antes de intentar nuevamente."

**Prerequisites:** Story 3.3 completada

**Technical Notes:**
- Implementar en `backend/app/routes/ia.py`
- Usar decorador `@rate_limit(max_requests=10, window_seconds=60)` personalizado
- Almacenar `sources_json` como JSON serializado en tabla queries
- Considerar almacenar hash de query para detectar duplicados exactos (cach√©)
- Agregar tests: consulta exitosa, query muy corta, query muy larga, rate limit excedido, LLM no disponible

---

### Story 3.5: Interfaz Conversacional (Estilo Chat) en Frontend

Como usuario,
Quiero una interfaz de chat intuitiva para consultar el conocimiento,
Para interactuar naturalmente con la IA y ver el historial de mis consultas.

**Acceptance Criteria:**

**Given** que estoy autenticado y en el dashboard (Story 1.4)
**When** implemento la interfaz de chat
**Then** existe una p√°gina `/chat` accesible desde el men√∫ principal

**And** la interfaz contiene:
- **√Årea de conversaci√≥n:** Panel scrolleable que muestra mensajes usuario/IA alternados
- **Input de consulta:**
  - Text area con placeholder: "Escribe tu pregunta aqu√≠... (ej. ¬øC√≥mo solicito vacaciones?)"
  - Contador de caracteres: "45 / 500"
  - Bot√≥n "Enviar" (o Enter para enviar)
- **Indicador de estado:**
  - Mientras IA procesa: muestra "IA est√° pensando..." con animaci√≥n de puntos
  - Estimaci√≥n de tiempo: "~2 segundos"

**And** el flujo de interacci√≥n:
1. Usuario escribe consulta y presiona "Enviar"
2. Consulta se agrega al √°rea de conversaci√≥n (burbuja azul a la derecha)
3. Aparece indicador "IA est√° pensando..."
4. Se env√≠a POST a `/api/ia/query`
5. Respuesta de IA aparece en burbuja gris a la izquierda con:
   - Texto de la respuesta
   - Secci√≥n "Fuentes consultadas" expandible con links a documentos
   - Iconos de feedback: üëç üëé
   - Timestamp: "Hace 2 minutos"

**And** muestra fuentes de manera visual:
```
üìÑ Fuentes consultadas (3):
  ‚Ä¢ Procedimiento Reembolsos (Relevancia: 92%)
  ‚Ä¢ Pol√≠ticas RRHH (Relevancia: 78%)
  ‚Ä¢ Manual de Procedimientos (Relevancia: 65%)
```
- Click en fuente ‚Üí abre vista previa del documento o descarga

**And** maneja errores de manera clara:
- Si error 503 (IA no disponible): Muestra mensaje "‚ö†Ô∏è El servicio de IA est√° temporalmente no disponible. Intenta en unos minutos."
- Si error 504 (timeout): "‚è±Ô∏è La consulta tard√≥ demasiado. Intenta con una pregunta m√°s espec√≠fica."
- Si error 429 (rate limit): "üö´ Has realizado muchas consultas. Espera un momento antes de continuar."

**And** el historial de conversaci√≥n:
- Persiste durante la sesi√≥n (almacenado en state del frontend)
- Se limpia al cerrar sesi√≥n o refrescar p√°gina (opcional para MVP: guardar en localStorage)
- Bot√≥n "Limpiar conversaci√≥n" visible

**And** dise√±o responsive:
- Funciona en desktop (1920x1080) y tablet (1024x768)
- En mobile (opcional para MVP): interfaz adaptada

**Prerequisites:** Story 3.4 completada

**Technical Notes:**
- Frontend: React 18 + TypeScript - crear componente `ChatInterface.tsx` con shadcn/ui
- Usar Axios para HTTP requests con interceptors (JWT token autom√°tico)
- Implementar scroll autom√°tico al √∫ltimo mensaje (auto-scroll down)
- Formatear respuestas con markdown b√°sico (negritas, listas, p√°rrafos)
- Usar biblioteca como `marked.js` o `react-markdown` para renderizar
- Agregar animaci√≥n suave de aparici√≥n de mensajes (fade-in)
- CSS: usar framework como Tailwind o custom CSS para burbujas de chat

---

### Story 3.6: Optimizaci√≥n de Rendimiento y Cach√© de Respuestas

Como sistema,
Quiero optimizar el tiempo de respuesta del motor de IA,
Para cumplir con el requerimiento no funcional de respuestas en <2 segundos.

**Acceptance Criteria:**

**Given** que el pipeline RAG est√° operativo (Story 3.3)
**When** implemento optimizaciones de rendimiento
**Then** el sistema alcanza las siguientes m√©tricas:

**M√©tricas Objetivo:**
- **P50 (mediana):** <1.5 segundos
- **P95 (percentil 95):** <2.5 segundos
- **P99 (percentil 99):** <5 segundos

**And** se implementan las siguientes optimizaciones:

**1. Cach√© de Respuestas:**
- Consultas id√©nticas (mismo texto) retornan respuesta cacheada
- TTL (Time To Live): 5 minutos
- Implementar con dict en memoria: `{query_hash: (response, timestamp)}`
- Limitar cach√© a 100 consultas m√°s recientes (LRU - Least Recently Used)

**2. Cach√© de Retrieval:**
- B√∫squedas id√©nticas retornan documentos cacheados
- TTL: 10 minutos (documentos cambian menos frecuentemente)

**3. Modelo Pre-cargado en Memoria:**
- Mantener Llama 3.1 cargado en memoria (evita latencia de inicializaci√≥n)
- Ollama mantiene modelo warm por defecto tras primera consulta
- Considerar `ollama run llama3.1:8b-instruct-q4_K_M` al iniciar servidor

**4. Paralelizaci√≥n:**
- Si recupera m√∫ltiples documentos: procesar extracci√≥n de snippets en paralelo (threading)

**5. Timeouts Configurables:**
- Timeout de b√∫squeda: 500ms (si excede, retorna parciales)
- Timeout de inferencia local: 10 segundos (luego lanza exception)

**6. Context Pruning:**
- Limitar contexto a m√°ximo 2000 tokens m√°s relevantes
- Reduce tiempo de inferencia (menos tokens a procesar)

**And** existe endpoint de m√©tricas (solo admin):
**GET /api/ia/metrics**
- Response:
  ```json
  {
    "total_queries": 150,
    "avg_response_time_ms": 1650,
    "p50_ms": 1500,
    "p95_ms": 2300,
    "p99_ms": 4200,
    "cache_hit_rate": 0.35,  // 35% de consultas servidas desde cach√©
    "avg_documents_retrieved": 2.8
  }
  ```

**And** se loggean m√©tricas detalladas:
- Tabla `performance_metrics`:
  - `query_id`, `retrieval_time_ms`, `llm_time_ms`, `total_time_ms`, `cache_hit`, `timestamp`
- Dashboard de admin muestra gr√°ficas de rendimiento (Growth Feature, en MVP solo endpoint JSON)

**And** si rendimiento <2s no es alcanzable:
- Documentar en `docs/limitaciones-tecnicas.md`:
  - Causas: velocidad de inferencia local limitada por CPU, memoria RAM disponible
  - Mediciones reales obtenidas (tokens/segundo en hardware de laboratorio)
  - Propuestas de mejora: GPU dedicada (NVIDIA), modelo m√°s peque√±o (3b), cuantizaci√≥n m√°s agresiva (q3)

**Prerequisites:** Story 3.5 completada

**Technical Notes:**
- Implementar cach√© con `functools.lru_cache` (Python built-in) o `cachetools` (m√°s control)
- Medir tiempos con `time.perf_counter()` (alta precisi√≥n)
- Almacenar m√©tricas en tabla para an√°lisis posterior
- Considerar usar Redis para cach√© distribuido (Growth Feature, no MVP)
- Implementar en `backend/app/services/performance_service.py`
- Agregar tests: cache hit, cache miss, m√©tricas calculadas correctamente

---

## Epic 4: Generaci√≥n Autom√°tica de Contenido Formativo

**Objetivo:** Extender las capacidades de la IA para generar autom√°ticamente material de capacitaci√≥n personalizado: res√∫menes, quizzes de evaluaci√≥n y learning paths. Este es el diferenciador clave que transforma el sistema de "asistente reactivo" a "generador proactivo de capacitaci√≥n".

**Valor de Negocio:** No solo responder preguntas, sino CREAR contenido formativo que acelera el aprendizaje organizacional y permite capacitaci√≥n personalizada a escala.

**Alineaci√≥n con PRD:** RF4 (Generaci√≥n de Contenido Formativo), Secci√≥n "Innovation & Novel Patterns" (Generaci√≥n autom√°tica de contenido formativo).

---

### Story 4.1: Generaci√≥n Autom√°tica de Res√∫menes de Documentos

Como usuario (admin o user),
Quiero generar autom√°ticamente un resumen ejecutivo de cualquier documento del repositorio,
Para comprender r√°pidamente los puntos clave sin leer el documento completo.

**Acceptance Criteria:**

**Given** que estoy autenticado y tengo acceso a un documento (Epic 2)
**When** implemento la funcionalidad de generaci√≥n de res√∫menes
**Then** existe el endpoint:

**POST /api/ia/generate/summary**
- Headers: `Authorization: Bearer {token}`
- Body:
  ```json
  {
    "document_id": 5,
    "summary_length": "short"  // opciones: "short" (150 palabras), "medium" (300 palabras), "long" (500 palabras)
  }
  ```
- Response 200:
  ```json
  {
    "document_id": 5,
    "document_title": "Manual de Procedimientos RRHH",
    "summary": "Este manual establece los procedimientos para...\n\nPuntos clave:\n- Solicitud de vacaciones requiere 15 d√≠as de anticipaci√≥n\n- Permisos m√©dicos se reportan dentro de 24 horas\n- Evaluaciones de desempe√±o se realizan semestralmente",
    "summary_length": "short",
    "word_count": 145,
    "generated_at": "2025-11-10T10:30:00Z",
    "generation_time_ms": 3200
  }
  ```

**And** el proceso de generaci√≥n:
1. Recupera el documento de la base de datos por `document_id`
2. Extrae `content_text` del documento (hasta 10,000 caracteres)
3. Construye prompt para el LLM:
   ```
   Eres un asistente experto en resumir documentos corporativos.

   Genera un resumen ejecutivo del siguiente documento en espa√±ol.
   Incluye los puntos clave m√°s importantes.
   Longitud objetivo: {summary_length_words} palabras.

   DOCUMENTO:
   {document_content}

   RESUMEN:
   ```
4. Env√≠a al LLM con par√°metros:
   - `temperature=0.5` (balance creatividad/determinismo)
   - `max_tokens` seg√∫n longitud: short=200, medium=400, long=600
5. Retorna resumen generado

**And** maneja casos especiales:
- **Documento no existe:** Response 404 "Documento no encontrado"
- **Documento sin contenido extra√≠do:** Response 400 "El documento no tiene contenido procesado. Intenta m√°s tarde."
- **Documento muy corto (<100 palabras):** Response 400 "El documento es demasiado corto para resumir. L√©elo directamente."
- **LLM falla:** Response 503 "Servicio de IA no disponible"

**And** almacena resumen generado:
- Crea tabla `generated_content`:
  - `id`, `document_id`, `user_id`, `content_type` ('summary'/'quiz'/'learning_path'), `content_json`, `created_at`
- Permite reusar res√∫menes: si mismo documento + misma longitud ‚Üí retorna cached (v√°lido 24 horas)

**And** incluye disclaimer:
- Agrega al final del resumen: "\n\n*Resumen generado autom√°ticamente por IA. Revisa el documento completo para detalles precisos.*"

**Prerequisites:** Epic 3 completada (especialmente Story 3.1 integraci√≥n LLM)

**Technical Notes:**
- Implementar en `backend/app/routes/ia.py`
- Reusar servicio de LLM de Story 3.1 (`ai_service.py`)
- Limitar contenido de entrada al LLM a 10,000 caracteres (evitar exceder l√≠mite de tokens)
- Si documento >10,000 chars: usar primeros 10,000 + advertencia en resumen "Nota: Resumen basado en secci√≥n inicial del documento"
- Agregar tests: generaci√≥n exitosa short/medium/long, documento no existe, documento sin contenido, cach√©

---

### Story 4.2: Generaci√≥n Autom√°tica de Quizzes de Evaluaci√≥n

Como administrador,
Quiero generar autom√°ticamente quizzes de opci√≥n m√∫ltiple basados en documentos,
Para evaluar la comprensi√≥n de los empleados sobre el conocimiento corporativo.

**Acceptance Criteria:**

**Given** que estoy autenticado como administrador
**When** implemento la funcionalidad de generaci√≥n de quizzes
**Then** existe el endpoint:

**POST /api/ia/generate/quiz**
- Headers: `Authorization: Bearer {admin_token}`
- Body:
  ```json
  {
    "document_id": 5,
    "num_questions": 5,  // opciones: 5, 10, 15
    "difficulty": "medium"  // opciones: "easy", "medium", "hard"
  }
  ```
- Response 200:
  ```json
  {
    "document_id": 5,
    "document_title": "Manual de Procedimientos RRHH",
    "quiz": {
      "title": "Quiz: Manual de Procedimientos RRHH",
      "num_questions": 5,
      "difficulty": "medium",
      "questions": [
        {
          "question_number": 1,
          "question": "¬øCon cu√°ntos d√≠as de anticipaci√≥n se debe solicitar vacaciones?",
          "options": [
            "A) 5 d√≠as",
            "B) 10 d√≠as",
            "C) 15 d√≠as",
            "D) 30 d√≠as"
          ],
          "correct_answer": "C",
          "explanation": "Seg√∫n el manual, las vacaciones requieren 15 d√≠as de anticipaci√≥n para aprobaci√≥n."
        }
      ]
    },
    "generated_at": "2025-11-10T10:30:00Z",
    "generation_time_ms": 8500
  }
  ```

**And** el proceso de generaci√≥n:
1. Recupera documento por `document_id`
2. Extrae `content_text`
3. Construye prompt para el LLM:
   ```
   Eres un experto en evaluaci√≥n educativa.

   Genera un quiz de opci√≥n m√∫ltiple basado en el siguiente documento.

   Requisitos:
   - {num_questions} preguntas
   - Dificultad: {difficulty}
   - 4 opciones por pregunta (A, B, C, D)
   - Solo 1 opci√≥n correcta por pregunta
   - Incluye explicaci√≥n breve de la respuesta correcta
   - Preguntas claras y espec√≠ficas sobre el contenido

   DOCUMENTO:
   {document_content}

   Formato de respuesta JSON:
   {
     "questions": [
       {
         "question": "...",
         "options": ["A) ...", "B) ...", "C) ...", "D) ..."],
         "correct_answer": "C",
         "explanation": "..."
       }
     ]
   }
   ```
4. Env√≠a al LLM con prompt estructurado para generar JSON
5. Parsea JSON retornado y valida estructura (usar try/except para manejo robusto)

**And** valida el quiz generado:
- Cada pregunta tiene exactamente 4 opciones
- `correct_answer` est√° en ["A", "B", "C", "D"]
- Todas las preguntas tienen explicaci√≥n
- Si validaci√≥n falla: reintenta generaci√≥n 1 vez, si falla nuevamente ‚Üí error 500

**And** maneja restricciones:
- **Solo administradores** pueden generar quizzes (usuarios normales: 403 Forbidden)
- Documento debe tener >500 palabras (si no: 400 "Documento muy corto para generar quiz significativo")
- `num_questions` no puede exceder 1 pregunta por cada 100 palabras del documento

**And** almacena quiz generado:
- Guarda en tabla `generated_content` con `content_type='quiz'`
- `content_json` almacena estructura completa del quiz

**And** existe endpoint para recuperar quizzes generados:
**GET /api/ia/generated/quizzes?document_id=5**
- Lista quizzes previamente generados para un documento

**Prerequisites:** Story 4.1 completada

**Technical Notes:**
- Implementar en `backend/app/routes/ia.py`
- Usar Llama 3.1 con prompt estructurado y formato JSON expl√≠cito
- Parsear JSON con manejo robusto de errores (try/except json.JSONDecodeError)
- Tiempo de generaci√≥n estimado: ~2-3 segundos por pregunta (5 preguntas = ~10-15 segundos)
- Si LLM no retorna JSON v√°lido: intentar extraer con regex como fallback o solicitar regeneraci√≥n
- Agregar tests: generaci√≥n exitosa 5/10/15 preguntas, validaci√≥n de estructura, solo admin
- Considerar agregar en prompt: "Responde √öNICAMENTE con JSON v√°lido, sin texto adicional"

---

### Story 4.3: Interfaz de Visualizaci√≥n y Respuesta de Quizzes

Como usuario,
Quiero responder interactivamente a quizzes generados y ver mi puntuaci√≥n,
Para evaluar mi comprensi√≥n del conocimiento corporativo.

**Acceptance Criteria:**

**Given** que existe un quiz generado (Story 4.2)
**When** implemento la interfaz de quiz
**Then** existe una p√°gina `/quiz/{quiz_id}` accesible para usuarios autenticados

**And** la p√°gina muestra:
- **Encabezado:** T√≠tulo del quiz + documento origen
- **Indicador de progreso:** "Pregunta 3 de 10"
- **Pregunta actual:** Texto de la pregunta claramente visible
- **Opciones:** Radio buttons para las 4 opciones (A, B, C, D)
- **Botones de navegaci√≥n:**
  - "Siguiente" (si no es √∫ltima pregunta)
  - "Finalizar Quiz" (si es √∫ltima pregunta)
  - "Anterior" (permite revisar respuestas previas)

**And** el flujo de respuesta:
1. Usuario selecciona una opci√≥n (radio button)
2. Click "Siguiente" ‚Üí guarda respuesta localmente (frontend state)
3. Carga siguiente pregunta
4. Repite hasta √∫ltima pregunta
5. Click "Finalizar Quiz" ‚Üí env√≠a todas las respuestas al backend

**And** existe endpoint para evaluar quiz:
**POST /api/ia/quiz/{quiz_id}/submit**
- Headers: `Authorization: Bearer {token}`
- Body:
  ```json
  {
    "answers": {
      "1": "C",
      "2": "A",
      "3": "B",
      "4": "C",
      "5": "D"
    }
  }
  ```
- Response 200:
  ```json
  {
    "quiz_id": 12,
    "score": 4,
    "total_questions": 5,
    "percentage": 80,
    "passed": true,  // si score >= 70%
    "results": [
      {
        "question_number": 1,
        "user_answer": "C",
        "correct_answer": "C",
        "is_correct": true,
        "explanation": "..."
      },
      {
        "question_number": 2,
        "user_answer": "A",
        "correct_answer": "B",
        "is_correct": false,
        "explanation": "..."
      }
    ]
  }
  ```

**And** la p√°gina de resultados muestra:
- **Puntuaci√≥n:** "4 de 5 correctas (80%)"
- **Badge visual:** "¬°Aprobado!" (verde) o "Necesitas mejorar" (amarillo) si <70%
- **Desglose por pregunta:**
  - ‚úÖ Pregunta 1: Correcta
  - ‚ùå Pregunta 2: Incorrecta (Tu respuesta: A, Correcta: B)
  - Explicaci√≥n de cada respuesta
- **Botones:**
  - "Reintentar Quiz"
  - "Volver al Documento"
  - "Ver otros Quizzes"

**And** almacena resultados:
- Tabla `quiz_attempts`:
  - `id`, `quiz_id`, `user_id`, `answers_json`, `score`, `total_questions`, `percentage`, `timestamp`
- Permite rastrear progreso de aprendizaje de usuarios

**Prerequisites:** Story 4.2 completada

**Technical Notes:**
- Implementar frontend en React 18 + TypeScript con componentes shadcn/ui
- Usar localStorage para guardar progreso temporal (evitar p√©rdida si cierra pesta√±a)
- Implementar timer opcional: "Tiempo estimado: 5 minutos"
- No mostrar respuestas correctas hasta finalizar (prevenir trampa)
- CSS: dise√±o limpio estilo plataforma educativa (ej. Kahoot, Quizlet)
- Agregar tests: navegaci√≥n entre preguntas, submit quiz, c√°lculo de puntuaci√≥n

---

### Story 4.4: Sugerencia de Learning Paths (Rutas de Aprendizaje)

Como usuario,
Quiero que la IA sugiera una ruta de aprendizaje personalizada sobre un tema,
Para saber qu√© documentos estudiar y en qu√© orden para dominar un √°rea de conocimiento.

**Acceptance Criteria:**

**Given** que estoy autenticado
**When** solicito un learning path sobre un tema
**Then** existe el endpoint:

**POST /api/ia/generate/learning-path**
- Headers: `Authorization: Bearer {token}`
- Body:
  ```json
  {
    "topic": "procedimientos de reembolsos",
    "user_level": "beginner"  // opciones: "beginner", "intermediate", "advanced"
  }
  ```
- Response 200:
  ```json
  {
    "topic": "procedimientos de reembolsos",
    "user_level": "beginner",
    "learning_path": {
      "title": "Ruta de Aprendizaje: Procedimientos de Reembolsos",
      "estimated_time_hours": 3,
      "steps": [
        {
          "step_number": 1,
          "title": "Conceptos b√°sicos de reembolsos",
          "document_id": 3,
          "document_title": "Introducci√≥n a Pol√≠ticas RRHH",
          "estimated_time_minutes": 20,
          "why_this_step": "Establece fundamentos antes de procedimientos espec√≠ficos"
        },
        {
          "step_number": 2,
          "title": "Procedimiento est√°ndar de reembolsos",
          "document_id": 5,
          "document_title": "Procedimiento de Reembolsos",
          "estimated_time_minutes": 45,
          "why_this_step": "Detalla el proceso paso a paso"
        },
        {
          "step_number": 3,
          "title": "Casos especiales y urgentes",
          "document_id": 8,
          "document_title": "Manual de Procedimientos Especiales",
          "estimated_time_minutes": 30,
          "why_this_step": "Cubre excepciones y casos avanzados"
        },
        {
          "step_number": 4,
          "title": "Evaluaci√≥n de conocimientos",
          "quiz_id": 12,
          "quiz_title": "Quiz: Procedimientos de Reembolsos",
          "estimated_time_minutes": 15,
          "why_this_step": "Valida tu comprensi√≥n del tema"
        }
      ]
    },
    "generated_at": "2025-11-10T10:30:00Z"
  }
  ```

**And** el proceso de generaci√≥n:
1. Busca documentos relevantes usando retrieval de Story 3.2:
   - `retrieve_relevant_documents(topic, top_k=10)`
2. Filtra documentos por relevancia (score >0.3)
3. Construye prompt para el LLM:
   ```
   Eres un experto en dise√±o instruccional.

   Crea una ruta de aprendizaje personalizada para el siguiente tema.

   TEMA: {topic}
   NIVEL DEL USUARIO: {user_level}

   DOCUMENTOS DISPONIBLES:
   1. {doc1_title} - {doc1_snippet}
   2. {doc2_title} - {doc2_snippet}
   ...

   Genera una secuencia de aprendizaje l√≥gica:
   - Para beginners: empezar con fundamentos
   - Para intermediate: enfocarse en aplicaci√≥n pr√°ctica
   - Para advanced: casos complejos y excepciones

   Para cada paso, indica:
   - Qu√© documento leer
   - Por qu√© es importante en esta secuencia
   - Tiempo estimado de estudio

   Formato JSON:
   {...}
   ```
4. Parsea respuesta del LLM
5. Agrega quiz al final (si existe quiz generado para documentos relevantes)

**And** valida el learning path:
- M√≠nimo 2 pasos, m√°ximo 8 pasos (secuencia manejable)
- Cada paso referencia un documento v√°lido existente
- Orden l√≥gico: fundamentos ‚Üí aplicaci√≥n ‚Üí casos avanzados
- Si no hay suficientes documentos relevantes: Response 400 "No se encontraron documentos suficientes sobre '{topic}'. Intenta con otro tema."

**And** almacena learning path:
- Tabla `generated_content` con `content_type='learning_path'`
- Permite rastrear qu√© usuarios generaron qu√© paths (anal√≠tica de intereses)

**And** existe interfaz visual del learning path:
**GET /learning-path/{path_id}**
- P√°gina con roadmap visual (timeline vertical o cards horizontales)
- Click en cada paso ‚Üí navega al documento o quiz
- Checkbox para marcar completados (progreso guardado en localStorage)

**Prerequisites:** Story 4.3 completada

**Technical Notes:**
- Reusar retrieval service de Epic 3
- Usar GPT-4 para mejor planificaci√≥n secuencial (GPT-3.5 puede funcionar con prompt bien dise√±ado)
- Estimar tiempos basado en longitud de documentos: ~5 min por 1000 palabras
- Visualizaci√≥n: usar biblioteca como `react-vertical-timeline` o custom CSS
- Agregar tests: generaci√≥n exitosa, sin documentos relevantes, validaci√≥n de estructura

---

### Story 4.5: Dashboard de Contenido Generado para Administradores

Como administrador,
Quiero ver un dashboard de todo el contenido generado por IA,
Para monitorear la calidad y uso de res√∫menes, quizzes y learning paths.

**Acceptance Criteria:**

**Given** que estoy autenticado como administrador
**When** accedo al dashboard de contenido generado
**Then** existe una p√°gina `/admin/generated-content` con las siguientes secciones:

**1. M√©tricas Generales:**
```
üìä Resumen de Contenido Generado
- Total de res√∫menes: 45
- Total de quizzes: 12
- Total de learning paths: 8
- Contenido generado esta semana: 15 items
```

**2. Lista de Contenido Generado:**
Tabla con columnas:
- ID | Tipo (Resumen/Quiz/Path) | Documento Origen | Generado por | Fecha | Acciones

**3. Filtros:**
- Por tipo de contenido (res√∫menes, quizzes, learning paths)
- Por rango de fechas
- Por documento origen
- Por usuario que gener√≥

**And** existe endpoint:
**GET /api/admin/generated-content**
- Headers: `Authorization: Bearer {admin_token}`
- Query params: `?type=quiz&limit=20&offset=0`
- Response:
  ```json
  {
    "total": 12,
    "items": [
      {
        "id": 15,
        "type": "quiz",
        "document_id": 5,
        "document_title": "Procedimiento de Reembolsos",
        "created_by": "admin",
        "created_at": "2025-11-10T10:30:00Z",
        "usage_count": 8  // cu√°ntas veces se ha usado/respondido
      }
    ]
  }
  ```

**And** para cada quiz muestra estad√≠sticas de uso:
**GET /api/admin/quiz/{quiz_id}/stats**
- Response:
  ```json
  {
    "quiz_id": 12,
    "total_attempts": 25,
    "avg_score_percentage": 78,
    "pass_rate": 0.84,  // 84% de intentos >=70%
    "most_difficult_question": {
      "question_number": 3,
      "correct_rate": 0.48
    }
  }
  ```

**And** permite acciones administrativas:
- **Ver:** Abre vista previa del contenido
- **Editar:** Permite modificar manualmente el contenido generado (opcional MVP)
- **Eliminar:** Borra el contenido generado (con confirmaci√≥n)
- **Exportar:** Descarga como PDF o JSON

**And** muestra gr√°ficas de tendencias (opcional MVP, en MVP solo tabla):
- Contenido generado por semana (line chart)
- Tipos de contenido m√°s generados (pie chart)
- Documentos con m√°s contenido generado (bar chart)

**Prerequisites:** Stories 4.1, 4.2, 4.3, 4.4 completadas

**Technical Notes:**
- Implementar en `backend/app/routes/admin.py`
- Solo accesible para rol 'admin' (decorador `@require_role('admin')`)
- Usar joins SQL para obtener estad√≠sticas eficientemente
- Exportar quiz a PDF: usar biblioteca `reportlab` o `weasyprint`
- Dashboard UI: crear custom React admin dashboard con componentes shadcn/ui (Card, Table, Dialog)
- Agregar tests: listado, filtros, estad√≠sticas, solo admin puede acceder

---

## Epic 5: Seguridad, Cumplimiento Normativo y Auditor√≠a

**Objetivo:** Garantizar que el sistema cumpla con todas las regulaciones chilenas (Ley 19.628, Ley 21.180) y est√°ndares internacionales (ISO 27001) mediante controles de seguridad robustos, cifrado, auditor√≠a completa y anonimizaci√≥n de datos personales.

**Valor de Negocio:** Sin cumplimiento normativo, el prototipo no es viable para implementaci√≥n real. Esta √©pica asegura la viabilidad legal y la confianza en el manejo de datos sensibles.

**Alineaci√≥n con PRD:** RS1-RS5 (Requerimientos de Seguridad), RF6-RF8, Secci√≥n "Domain-Specific Requirements" (Cumplimiento Normativo).

---

### Story 5.1: Gesti√≥n de Usuarios y Roles (RBAC Completo)

Como administrador,
Quiero gestionar usuarios del sistema con roles claramente definidos,
Para controlar el acceso a funcionalidades sensibles seg√∫n el principio de privilegio m√≠nimo.

**Acceptance Criteria:**

**Given** que estoy autenticado como administrador
**When** implemento la gesti√≥n completa de usuarios
**Then** existen los siguientes endpoints:

**POST /api/admin/users** (crear usuario)
- Headers: `Authorization: Bearer {admin_token}`
- Body:
  ```json
  {
    "username": "juan.perez",
    "password": "SecurePass123!",
    "full_name": "Juan P√©rez Gonz√°lez",
    "email": "juan.perez@banmedica.cl",
    "role": "user"  // "admin" o "user"
  }
  ```
- Response 201:
  ```json
  {
    "user_id": 5,
    "username": "juan.perez",
    "full_name": "Juan P√©rez Gonz√°lez",
    "email": "juan.perez@banmedica.cl",
    "role": "user",
    "is_active": true,
    "created_at": "2025-11-10T10:30:00Z"
  }
  ```

**GET /api/admin/users** (listar usuarios)
- Response 200:
  ```json
  {
    "total": 12,
    "users": [
      {
        "user_id": 5,
        "username": "juan.perez",
        "full_name": "Juan P√©rez Gonz√°lez",
        "role": "user",
        "is_active": true,
        "last_login": "2025-11-09T15:30:00Z"
      }
    ]
  }
  ```

**PUT /api/admin/users/{user_id}** (actualizar usuario)
- Permite modificar: `full_name`, `email`, `role`, `is_active`
- NO permite modificar: `username` (es √∫nico e inmutable)
- Response 200: usuario actualizado

**PATCH /api/admin/users/{user_id}/deactivate** (desactivar usuario)
- Marca `is_active=False` (soft delete, mantiene trazabilidad)
- Usuario desactivado no puede hacer login
- Response 200: `{"message": "Usuario desactivado exitosamente"}`

**POST /api/users/change-password** (cambiar contrase√±a - cualquier usuario)
- Headers: `Authorization: Bearer {token}`
- Body:
  ```json
  {
    "current_password": "OldPass123!",
    "new_password": "NewSecurePass456!"
  }
  ```
- Valida contrase√±a actual antes de cambiar
- Response 200: `{"message": "Contrase√±a actualizada exitosamente"}`

**And** implementa validaci√≥n de contrase√±as seguras:
- M√≠nimo 8 caracteres
- Al menos 1 may√∫scula, 1 min√∫scula, 1 n√∫mero, 1 car√°cter especial
- No debe ser igual al username
- Si validaci√≥n falla: Response 400 con mensaje espec√≠fico del error

**And** modelo `User` extendido contiene:
- `id`, `username` (unique), `password_hash`, `full_name`, `email`, `role`, `is_active`, `created_at`, `last_login`, `failed_login_attempts`, `locked_until`

**And** registra eventos en audit logs:
- "USER_CREATED", "USER_UPDATED", "USER_DEACTIVATED", "PASSWORD_CHANGED"

**Prerequisites:** Epic 1 completada (base de autenticaci√≥n existe)

**Technical Notes:**
- Validar passwords con librer√≠a `password-strength` o regex personalizado
- Hash passwords con bcrypt (work factor = 12)
- NO retornar `password_hash` en ning√∫n endpoint (nunca exponer hashes)
- Email debe ser √∫nico (constraint en base de datos)
- Implementar en `backend/app/routes/admin.py` y `backend/app/routes/users.py`
- Agregar tests: crear usuario, validaci√≥n de password d√©bil, desactivar usuario, cambiar contrase√±a

---

### Story 5.2: Sistema de Bloqueo de Cuentas por Intentos Fallidos

Como sistema,
Quiero bloquear temporalmente cuentas tras m√∫ltiples intentos fallidos de login,
Para prevenir ataques de fuerza bruta y proteger cuentas de usuarios.

**Acceptance Criteria:**

**Given** que un usuario intenta hacer login
**When** implemento el sistema de protecci√≥n anti-brute force
**Then** el flujo de login (Story 1.3) se extiende con:

**L√≥gica de intentos fallidos:**
1. Usuario env√≠a credenciales a `/api/auth/login`
2. Si credenciales son **incorrectas**:
   - Incrementa `User.failed_login_attempts` en 1
   - Si `failed_login_attempts >= 5`:
     - Marca `User.locked_until = now() + 15 minutos`
     - Response 403:
       ```json
       {
         "error": {
           "code": "ACCOUNT_LOCKED",
           "message": "Cuenta bloqueada temporalmente por m√∫ltiples intentos fallidos. Intenta nuevamente en 15 minutos.",
           "locked_until": "2025-11-10T10:45:00Z"
         }
       }
       ```
   - Si `failed_login_attempts < 5`:
     - Response 401:
       ```json
       {
         "error": {
           "code": "INVALID_CREDENTIALS",
           "message": "Usuario o contrase√±a incorrectos",
           "remaining_attempts": 3  // 5 - failed_login_attempts
         }
       }
       ```
3. Si credenciales son **correctas**:
   - Resetea `failed_login_attempts = 0`
   - Actualiza `last_login = now()`
   - Genera token JWT normalmente

**And** si cuenta est√° bloqueada (`locked_until > now()`):
- Response 403 inmediata sin validar credenciales (prevenir timing attacks)
- Mensaje indica tiempo restante de bloqueo

**And** bloqueo expira autom√°ticamente:
- Si `now() > locked_until`: resetea `locked_until = NULL` y `failed_login_attempts = 0`
- Usuario puede intentar login nuevamente

**And** administrador puede desbloquear cuenta manualmente:
**POST /api/admin/users/{user_id}/unlock**
- Resetea `failed_login_attempts = 0` y `locked_until = NULL`
- Response 200: `{"message": "Cuenta desbloqueada exitosamente"}`

**And** registra eventos en audit logs:
- "LOGIN_FAILED" (cada intento fallido)
- "ACCOUNT_LOCKED" (cuando se bloquea)
- "ACCOUNT_UNLOCKED" (manual por admin o autom√°tico)

**And** configuraci√≥n de bloqueo es personalizable:
- Variables en `.env`:
  ```
  MAX_FAILED_LOGIN_ATTEMPTS=5
  ACCOUNT_LOCKOUT_MINUTES=15
  ```

**Prerequisites:** Story 5.1 completada

**Technical Notes:**
- Implementar middleware de verificaci√≥n de bloqueo antes de validar credenciales
- Usar transacciones de base de datos para incrementos at√≥micos (evitar race conditions)
- Loggear IP address en intentos fallidos (detecci√≥n de ataques distribuidos)
- Opcional: implementar CAPTCHA tras 3 intentos fallidos (Growth Feature)
- Agregar tests: 5 intentos fallidos ‚Üí bloqueo, desbloqueo autom√°tico tras 15 min, desbloqueo manual

---

### Story 5.3: Cifrado de Datos en Reposo y en Tr√°nsito

Como desarrollador de seguridad,
Quiero cifrar datos sensibles en reposo y todas las comunicaciones en tr√°nsito,
Para cumplir con RS4 y proteger la confidencialidad de informaci√≥n corporativa.

**Acceptance Criteria:**

**Given** que el sistema maneja datos sensibles
**When** implemento cifrado completo
**Then** se configuran las siguientes medidas:

**1. Cifrado en Tr√°nsito (HTTPS):**
- Todas las comunicaciones HTTP usan TLS 1.2+ (HTTPS)
- Certificado SSL/TLS configurado:
  - **Laboratorio/desarrollo:** Certificado auto-firmado (generado con OpenSSL)
  - **Producci√≥n (futuro):** Certificado v√°lido de CA (Let's Encrypt)
- Configuraci√≥n FastAPI fuerza HTTPS en producci√≥n:
  ```python
  app.config['SESSION_COOKIE_SECURE'] = True  # Cookies solo sobre HTTPS
  app.config['SESSION_COOKIE_HTTPONLY'] = True  # Prevenir XSS
  app.config['SESSION_COOKIE_SAMESITE'] = 'Lax'  # Prevenir CSRF
  ```
- Redireccionamiento autom√°tico HTTP ‚Üí HTTPS (middleware)

**2. Cifrado en Reposo (Base de Datos):**
- Base de datos SQLite cifrada usando extensi√≥n SQLCipher:
  ```sql
  PRAGMA key = 'your-encryption-key-from-env';
  ```
- Clave de cifrado almacenada en `.env`:
  ```
  DB_ENCRYPTION_KEY=your-256-bit-encryption-key-here
  ```
- Si migra a PostgreSQL (futuro): usar cifrado de disco completo o pgcrypto

**3. Cifrado de Campos Sensibles (Opcional en MVP, recomendado):**
- Campos que contienen PII (Personally Identifiable Information):
  - `User.email` ‚Üí cifrado con AES-256
  - `AuditLog.details` ‚Üí cifrado si contiene datos sensibles
- Usar biblioteca `cryptography` (Python):
  ```python
  from cryptography.fernet import Fernet
  cipher = Fernet(DB_FIELD_ENCRYPTION_KEY)
  encrypted_email = cipher.encrypt(email.encode())
  ```

**And** existe script de inicializaci√≥n de claves:
**`scripts/generate_encryption_keys.py`**
- Genera claves criptogr√°ficas seguras:
  - `SECRET_KEY` (JWT)
  - `DB_ENCRYPTION_KEY` (SQLCipher)
  - `DB_FIELD_ENCRYPTION_KEY` (Fernet)
- Output: claves en formato seguro para copiar a `.env`

**And** documentaci√≥n de seguridad:
**`docs/seguridad.md`** contiene:
- C√≥mo generar certificado SSL auto-firmado
- C√≥mo configurar HTTPS en entorno de desarrollo
- C√≥mo rotar claves de cifrado
- Pol√≠tica de gesti√≥n de secretos

**And** validaci√≥n de configuraci√≥n:
- Script de health check valida:
  - HTTPS est√° habilitado
  - Base de datos est√° cifrada
  - Claves de cifrado est√°n configuradas (no valores por defecto)
- Si falla: sistema no inicia (fail-secure)

**Prerequisites:** Epic 1 completada

**Technical Notes:**
- **SQLCipher:** Reemplazar `sqlite3` con `pysqlcipher3` en requirements.txt
- **Certificado auto-firmado:** Generar con `openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days 365 -nodes`
- **Claves:** Usar `secrets.token_urlsafe(32)` para generar claves seguras
- **IMPORTANTE:** `.env` NUNCA en Git (ya configurado en Story 1.5)
- Documentar c√≥mo manejar claves en producci√≥n (ej. AWS Secrets Manager, HashiCorp Vault)
- Agregar tests: HTTPS redirect funciona, base de datos cifrada, cifrado de campos sensibles

---

### Story 5.4: Sistema de Auditor√≠a Completo con Logs Estructurados

Como auditor/administrador,
Quiero que todas las acciones sensibles del sistema queden registradas en logs de auditor√≠a,
Para tener trazabilidad completa y cumplir con RS3 y Ley 19.628.

**Acceptance Criteria:**

**Given** que el sistema tiene la tabla `audit_logs` (creada en Story 1.2)
**When** extiendo el sistema de auditor√≠a
**Then** se registran los siguientes tipos de eventos:

**Eventos de Autenticaci√≥n:**
- `LOGIN_SUCCESS`, `LOGIN_FAILED`, `LOGOUT`, `PASSWORD_CHANGED`, `ACCOUNT_LOCKED`, `ACCOUNT_UNLOCKED`

**Eventos de Gesti√≥n de Conocimiento:**
- `DOCUMENT_UPLOADED`, `DOCUMENT_DOWNLOADED`, `DOCUMENT_DELETED`, `DOCUMENT_VIEWED`

**Eventos de IA:**
- `AI_QUERY`, `SUMMARY_GENERATED`, `QUIZ_GENERATED`, `LEARNING_PATH_GENERATED`, `QUIZ_SUBMITTED`

**Eventos de Administraci√≥n:**
- `USER_CREATED`, `USER_UPDATED`, `USER_DEACTIVATED`, `ROLE_CHANGED`

**Eventos de Seguridad:**
- `UNAUTHORIZED_ACCESS_ATTEMPT`, `PERMISSION_DENIED`, `INVALID_TOKEN`, `SUSPICIOUS_ACTIVITY`

**And** cada log contiene campos estructurados:
```python
{
  "id": 1234,
  "timestamp": "2025-11-10T10:30:00.123456Z",
  "event_type": "AI_QUERY",
  "user_id": 5,
  "username": "juan.perez",
  "ip_address": "192.168.1.100",
  "user_agent": "Mozilla/5.0...",
  "resource": "query_12345",
  "action": "CREATE",
  "status": "success",  // "success", "failure", "error"
  "details": {
    "query": "¬øC√≥mo solicito vacaciones?",
    "response_time_ms": 1850,
    "sources_count": 3
  },
  "severity": "INFO"  // "DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"
}
```

**And** implementa helper function para logging:
```python
def audit_log(
    event_type: str,
    user_id: int,
    resource: str,
    action: str,
    status: str = "success",
    details: dict = None,
    severity: str = "INFO"
):
    # Captura IP y User-Agent del request actual
    # Inserta en tabla audit_logs
    # Loggea tambi√©n en archivo de logs (opcional)
```

**And** existe endpoint de consulta de logs (solo admin):
**GET /api/admin/audit-logs**
- Query params:
  - `?event_type=AI_QUERY` (filtrar por tipo de evento)
  - `?user_id=5` (filtrar por usuario)
  - `?start_date=2025-11-01&end_date=2025-11-10` (rango de fechas)
  - `?severity=ERROR` (filtrar por severidad)
  - `?limit=50&offset=0` (paginaci√≥n)
- Response 200:
  ```json
  {
    "total": 1523,
    "logs": [
      {
        "id": 1234,
        "timestamp": "2025-11-10T10:30:00Z",
        "event_type": "AI_QUERY",
        "username": "juan.perez",
        "resource": "query_12345",
        "status": "success"
      }
    ]
  }
  ```

**And** logs se exportan para an√°lisis externo:
**GET /api/admin/audit-logs/export?format=csv**
- Genera CSV con todos los logs (o filtrados)
- Headers: `Content-Disposition: attachment; filename="audit_logs_20251110.csv"`

**And** pol√≠tica de retenci√≥n de logs:
- Logs se mantienen por m√≠nimo 6 meses (configurable en `.env`)
- Script de limpieza autom√°tica: `scripts/cleanup_old_logs.py`
- Ejecutar mensualmente (cronjob o tarea programada)

**And** alertas de seguridad (opcional MVP):
- Si detecta >10 intentos fallidos de login desde misma IP en 5 minutos ‚Üí loggea `SUSPICIOUS_ACTIVITY`
- Si usuario intenta acceder a recurso sin permisos ‚Üí loggea `PERMISSION_DENIED`

**Prerequisites:** Story 5.2 completada

**Technical Notes:**
- Indexar columnas `timestamp`, `event_type`, `user_id` en tabla audit_logs (performance)
- Considerar rotar logs a archivos externos para largo plazo (ej. AWS S3, Elasticsearch)
- Usar Python `logging` module para logs de aplicaci√≥n + tabla DB para auditor√≠a
- Formato de timestamp: ISO 8601 con milisegundos y timezone UTC
- CSV export: usar biblioteca `csv` est√°ndar de Python
- Agregar tests: audit_log() inserta correctamente, filtros funcionan, export CSV

---

### Story 5.5: Anonimizaci√≥n de Datos Personales (Ley 19.628)

Como desarrollador de cumplimiento,
Quiero anonimizar datos personales en documentos de prueba y datos de auditor√≠a,
Para cumplir con la Ley 19.628 de protecci√≥n de datos personales y garantizar que el prototipo no contenga informaci√≥n real de personas.

**Acceptance Criteria:**

**Given** que el sistema maneja datos personales
**When** implemento anonimizaci√≥n de datos
**Then** existe un m√≥dulo `backend/app/services/anonymization_service.py` con funciones:

**1. Detecci√≥n de PII (Personally Identifiable Information):**
```python
def detect_pii(text: str) -> List[Dict]:
    """
    Detecta datos personales en texto.
    Retorna lista de PII encontrados: RUT, emails, tel√©fonos, nombres.
    """
    # Regex para RUT chileno: XX.XXX.XXX-X
    # Regex para email: nombre@dominio.cl
    # Regex para tel√©fono: +56 9 XXXX XXXX
    # NER (Named Entity Recognition) para nombres propios (opcional con spaCy)
```

**2. Anonimizaci√≥n autom√°tica:**
```python
def anonymize_text(text: str, method: str = "mask") -> str:
    """
    Anonimiza PII detectado.
    M√©todos:
    - "mask": reemplaza con "***" (ej. "12.345.678-9" ‚Üí "**.***.**-*")
    - "pseudonymize": reemplaza con identificador ficticio (ej. "Juan P√©rez" ‚Üí "Usuario_A123")
    - "synthetic": genera datos sint√©ticos realistas (ej. RUT v√°lido pero ficticio)
    """
```

**And** se aplica anonimizaci√≥n en:

**Documentos de prueba:**
- Al cargar documentos (Story 2.2), sistema detecta PII
- Si documento contiene PII:
  - Loggea warning: "Documento contiene datos personales detectados"
  - Ofrece al admin opci√≥n de anonimizar autom√°ticamente antes de indexar
  - Endpoint: `POST /api/knowledge/anonymize/{document_id}`

**Datos de auditor√≠a:**
- Antes de almacenar en `audit_logs.details`, anonimiza queries que contengan PII
- Ejemplo:
  - Original: `{"query": "¬øCu√°ndo tengo vacaciones Juan P√©rez RUT 12.345.678-9?"}`
  - Anonimizado: `{"query": "¬øCu√°ndo tengo vacaciones [NOMBRE] RUT [RUT]?"}`


**And** existe herramienta de auditor√≠a de PII:
**GET /api/admin/pii-scan**
- Escanea todos los documentos en busca de PII
- Response:
  ```json
  {
    "total_documents": 50,
    "documents_with_pii": 8,
    "pii_types_found": ["RUT", "email", "phone"],
    "documents": [
      {
        "document_id": 5,
        "title": "Manual RRHH",
        "pii_count": 12,
        "pii_types": ["RUT", "email"]
      }
    ]
  }
  ```

**And** validaci√≥n de cumplimiento:
- Script de validaci√≥n: `scripts/validate_compliance.py`
- Verifica:
  - ‚úÖ Ning√∫n documento contiene PII real sin anonimizar
  - ‚úÖ Logs de auditor√≠a no exponen datos personales en texto plano
  - ‚úÖ Datos de prueba utilizan informaci√≥n sint√©tica o anonimizada
- Output: reporte de cumplimiento PDF

**Prerequisites:** Epic 2 completada

**Technical Notes:**
- **Detecci√≥n de RUT:** Regex + validaci√≥n de d√≠gito verificador chileno
- **Detecci√≥n de nombres:** Usar spaCy con modelo espa√±ol `es_core_news_sm` (NER)
- **Alternativa ligera:** Regex + diccionario de nombres comunes chilenos
- **Faker para datos sint√©ticos:** Biblioteca `Faker` con locale `es_CL`
- **IMPORTANTE:** Esta funcionalidad protege contra filtraci√≥n accidental de PII en datos de prueba
- **Justificaci√≥n con modelo local:** Aunque los datos no salen del sistema, es buena pr√°ctica para:
  - Preparar datos de prueba limpios para el prototipo
  - Evitar almacenar PII real en logs que podr√≠an exportarse
  - Demostrar cumplimiento normativo en el informe de prefactibilidad
- Documentar proceso de anonimizaci√≥n en `docs/cumplimiento-ley-19628.md`
- Agregar tests: detecci√≥n de RUT, anonimizaci√≥n de email, scan de documentos

---

### Story 5.6: Control de Acceso Granular a Documentos (Opcional MVP)

Como administrador,
Quiero definir qu√© usuarios pueden acceder a qu√© categor√≠as de documentos,
Para implementar control de acceso granular basado en necesidad de conocer (need-to-know).

**Acceptance Criteria:**

**Given** que algunos documentos son sensibles o confidenciales
**When** implemento control de acceso a nivel de categor√≠a
**Then** se extiende el modelo de datos:

**Modelo `DocumentCategory` extendido:**
- `access_level` (String): "public", "internal", "confidential", "restricted"
- `allowed_roles` (JSON): Lista de roles permitidos, ej. `["admin", "manager"]`

**Modelo `UserPermissions` (nuevo):**
- `user_id` (FK ‚Üí User.id)
- `category_id` (FK ‚Üí DocumentCategory.id)
- `can_view` (Boolean)
- `can_download` (Boolean)

**And** l√≥gica de autorizaci√≥n:
- Al listar documentos (`GET /api/knowledge/documents`):
  - Filtra documentos seg√∫n categor√≠as accesibles para el rol/usuario
  - Usuario normal solo ve categor√≠as con `access_level = "public"` o permisos expl√≠citos
  - Admin ve todas las categor√≠as

- Al descargar documento (`GET /api/knowledge/documents/{id}/download`):
  - Verifica que usuario tiene `can_download=True` para esa categor√≠a
  - Si no: Response 403 "No tienes permisos para descargar documentos de esta categor√≠a"

- Al consultar IA (`POST /api/ia/query`):
  - Retrieval solo busca en documentos de categor√≠as accesibles para el usuario
  - Respuestas NO incluyen informaci√≥n de documentos restringidos

**And** administrador gestiona permisos:
**POST /api/admin/permissions/grant**
- Body:
  ```json
  {
    "user_id": 5,
    "category_id": 3,
    "can_view": true,
    "can_download": false
  }
  ```
- Otorga permiso espec√≠fico a usuario

**GET /api/admin/permissions/user/{user_id}**
- Lista todos los permisos de un usuario

**And** registra accesos a documentos restringidos:
- Logs de auditor√≠a incluyen `access_level` del documento
- Evento: `RESTRICTED_DOCUMENT_ACCESSED`

**And** categor√≠as predefinidas con niveles:
- "Pol√≠ticas RRHH" ‚Üí `public` (todos los usuarios)
- "Procedimientos Operativos" ‚Üí `internal` (usuarios autenticados)
- "Informaci√≥n Financiera" ‚Üí `confidential` (solo admin)
- "Datos Personales" ‚Üí `restricted` (requiere permiso expl√≠cito)

**Prerequisites:** Story 5.4 completada

**Technical Notes:**
- **Nota:** Esta historia es OPCIONAL para MVP, pero importante para producci√≥n
- Si tiempo limitado: implementar solo control a nivel de rol (admin vs user) sin permisos granulares
- Implementar middleware `@require_category_access(category_id)` para endpoints
- Modificar retrieval service para filtrar por categor√≠as accesibles
- Agregar tests: usuario sin permiso no ve documentos, admin ve todos, permisos granulares funcionan

---

