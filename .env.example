# Database Configuration
DATABASE_URL=sqlite:///./database/asistente_conocimiento.db
# DATABASE_URL=postgresql://user:password@localhost:5432/asistente_conocimiento

# Security - CRITICAL: Change these in production!
SECRET_KEY=your-secret-key-here-replace-with-secure-random-value-min-64-chars
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24

# Ollama / LLM Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b-instruct-q4_K_M
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=500
LLM_CONTEXT_SIZE=8192

# Performance & Caching Configuration (Story 3.6)
# Timeout for document retrieval search (returns partial results if exceeded)
RETRIEVAL_TIMEOUT_MS=500

# Timeout for LLM inference (raises exception if exceeded)
LLM_INFERENCE_TIMEOUT_S=10

# Cache TTL for identical queries (5 minutes)
RESPONSE_CACHE_TTL_SECONDS=300

# Cache TTL for document retrieval results (10 minutes)
RETRIEVAL_CACHE_TTL_SECONDS=600

# Maximum number of entries in LRU cache (response + retrieval separate)
MAX_CACHE_SIZE=100

# Maximum tokens in augmented context (context pruning, AC#5)
MAX_CONTEXT_TOKENS=2000

# Development Settings
FASTAPI_ENV=development
DEBUG=true
LOG_LEVEL=info

# CORS Settings
ALLOWED_ORIGINS=http://localhost:5173,http://127.0.0.1:5173
